{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.utils as utils\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "import tensorflow.keras.preprocessing.image as image\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('train_labels.csv',dtype= {'Id': 'str', 'Category': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(train_labels.shape[0]):\n",
    "    img = image.load_img('train/{}.jpg'.format(train_labels.iloc[i]['Id']),\n",
    "                                                target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    X.append(image.img_to_array(img)/255.0)\n",
    "    y.append(train_labels.iloc[i]['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "classes = {'rose': 0, 'sunflower': 1, 'daisy': 2, 'tulip': 3, 'dandelion': 4}\n",
    "yi = [classes[s] for s in y]\n",
    "y_sparse = to_categorical(yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(X, y_sparse, test_size=0.1, random_state=17, stratify=y_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freefly19/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.NASNetLarge(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = layers.SpatialDropout2D(0.2)(x)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "x = layers.Dense(4096, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "predictions = layers.Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "m = models.Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedSequence(utils.Sequence):\n",
    "  def __init__(self, X, y, batch_size):\n",
    "    self.X = np.array(X)\n",
    "    self.y = np.array(y)\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    #for shuffling\n",
    "    self.ids = np.random.permutation(range(len(X)))\n",
    "    \n",
    "    #for augmentation\n",
    "    self.seq = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.2),\n",
    "        iaa.Affine(scale=(0.8, 1.2), translate_percent=(-0.2, 0.2), rotate=(-45, 45), shear=(-16, 16))\n",
    "    ])\n",
    "    \n",
    "  def __len__(self):\n",
    "    return int(np.ceil(len(self.X)/float(self.batch_size)))\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    start = index * self.batch_size\n",
    "    end = np.minimum((index + 1) * self.batch_size, len(self.X))\n",
    "    \n",
    "    ids = self.ids[start:end]\n",
    "    \n",
    "    batchX = self.X[ids]\n",
    "    batchy = self.y[ids]\n",
    "    \n",
    "    batchX = self.seq.augment_images(batchX)\n",
    "    \n",
    "    return np.array(batchX), np.array(batchy)\n",
    "  \n",
    "  def on_epoch_end(self):    \n",
    "    self.ids = np.random.permutation(range(len(self.X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "341/341 [==============================] - 71s 208ms/step - loss: 0.1301 - acc: 0.9520 - val_loss: 0.2203 - val_acc: 0.9406\n",
      "Epoch 2/20\n",
      "341/341 [==============================] - 35s 104ms/step - loss: 0.1009 - acc: 0.9644 - val_loss: 0.2161 - val_acc: 0.9439\n",
      "Epoch 3/20\n",
      "341/341 [==============================] - 35s 104ms/step - loss: 0.1169 - acc: 0.9597 - val_loss: 0.2310 - val_acc: 0.9439\n",
      "Epoch 4/20\n",
      "341/341 [==============================] - 35s 103ms/step - loss: 0.1095 - acc: 0.9569 - val_loss: 0.2287 - val_acc: 0.9439\n",
      "Epoch 5/20\n",
      "341/341 [==============================] - 35s 104ms/step - loss: 0.1026 - acc: 0.9674 - val_loss: 0.2316 - val_acc: 0.9439\n",
      "Epoch 6/20\n",
      "341/341 [==============================] - 35s 104ms/step - loss: 0.1173 - acc: 0.9561 - val_loss: 0.2383 - val_acc: 0.9439\n",
      "Epoch 7/20\n",
      "341/341 [==============================] - 35s 104ms/step - loss: 0.1100 - acc: 0.9609 - val_loss: 0.2427 - val_acc: 0.9472\n",
      "Epoch 8/20\n",
      "341/341 [==============================] - 35s 104ms/step - loss: 0.1101 - acc: 0.9637 - val_loss: 0.2444 - val_acc: 0.9439\n",
      "Epoch 9/20\n",
      "341/341 [==============================] - 35s 104ms/step - loss: 0.1004 - acc: 0.9637 - val_loss: 0.2425 - val_acc: 0.9439\n",
      "Epoch 10/20\n",
      "341/341 [==============================] - 36s 104ms/step - loss: 0.0958 - acc: 0.9703 - val_loss: 0.2480 - val_acc: 0.9439\n",
      "Epoch 11/20\n",
      "341/341 [==============================] - 36s 104ms/step - loss: 0.0946 - acc: 0.9686 - val_loss: 0.2542 - val_acc: 0.9472\n",
      "Epoch 12/20\n",
      "341/341 [==============================] - 36s 104ms/step - loss: 0.1051 - acc: 0.9652 - val_loss: 0.2511 - val_acc: 0.9439\n",
      "Epoch 13/20\n",
      "341/341 [==============================] - 35s 104ms/step - loss: 0.0837 - acc: 0.9699 - val_loss: 0.2590 - val_acc: 0.9406\n",
      "Epoch 14/20\n",
      "341/341 [==============================] - 35s 103ms/step - loss: 0.0948 - acc: 0.9682 - val_loss: 0.2577 - val_acc: 0.9439\n",
      "Epoch 15/20\n",
      "341/341 [==============================] - 36s 105ms/step - loss: 0.0942 - acc: 0.9707 - val_loss: 0.2587 - val_acc: 0.9439\n",
      "Epoch 16/20\n",
      "341/341 [==============================] - 36s 105ms/step - loss: 0.0896 - acc: 0.9710 - val_loss: 0.2553 - val_acc: 0.9472\n",
      "Epoch 17/20\n",
      "341/341 [==============================] - 36s 105ms/step - loss: 0.0888 - acc: 0.9670 - val_loss: 0.2488 - val_acc: 0.9439\n",
      "Epoch 18/20\n",
      "341/341 [==============================] - 35s 104ms/step - loss: 0.0886 - acc: 0.9721 - val_loss: 0.2643 - val_acc: 0.9373\n",
      "Epoch 19/20\n",
      "341/341 [==============================] - 36s 104ms/step - loss: 0.0952 - acc: 0.9626 - val_loss: 0.2530 - val_acc: 0.9406\n",
      "Epoch 20/20\n",
      "341/341 [==============================] - 36s 104ms/step - loss: 0.0964 - acc: 0.9674 - val_loss: 0.2689 - val_acc: 0.9406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fade69cbc50>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "m.compile(optimizer=optimizers.Adam(1e-6),\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "m.fit_generator(AugmentedSequence(train_X, train_Y, 8), \n",
    "      validation_data=(val_X, val_Y),\n",
    "      epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/341 [..............................] - ETA: 3:51:24 - loss: 1.3142 - acc: 0.5000"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[512,512,3,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node res5b_branch2b_1/Conv2D}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@train...kpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_92/Relu, res5b_branch2b_1/Conv2D/ReadVariableOp)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_14/mul/_27343}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_20485_loss_14/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-1edaa7587f33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       callbacks=[\n\u001b[0;32m----> 9\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights-progress.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       ])\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 176\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[512,512,3,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node res5b_branch2b_1/Conv2D}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@train...kpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_92/Relu, res5b_branch2b_1/Conv2D/ReadVariableOp)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_14/mul/_27343}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_20485_loss_14/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "m.compile(optimizer=optimizers.Adam(1e-6),\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "m.fit_generator(AugmentedSequence(train_X, train_Y, 8), \n",
    "      validation_data=(val_X, val_Y),\n",
    "      epochs = 100,\n",
    "      callbacks=[\n",
    "          callbacks.ModelCheckpoint('weights-progress.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "m.compile(optimizer=optimizers.Adam(1e-8),\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "m.fit_generator(AugmentedSequence(np.concatenate((train_X, val_X)), np.concatenate((train_Y, val_Y)), 8), \n",
    "      validation_data=(val_X, val_Y),\n",
    "      epochs = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_num=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save_weights(f'weights-submission-{sub_num}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_X = []\n",
    "test_lebels = []\n",
    "for img_file in os.listdir('test'):\n",
    "    img = image.load_img('test/' + img_file, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    test_X.append(image.img_to_array(img)/255.0)\n",
    "    test_lebels.append(img_file.replace('.jpg', ''))\n",
    "test_X = np.asarray(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = m.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = tf.argmax(test_pred, axis=1).eval(session=tf.Session())\n",
    "reverted_classes = {classes[c]:c for c in classes}\n",
    "pred_classes = [reverted_classes[c] for c in class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'Category': pred_classes}, index=test_lebels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = 'Id'\n",
    "df.sort_index().to_csv(f'res-{sub_num}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
